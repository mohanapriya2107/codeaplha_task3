{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3483d703-86e9-4db4-95d0-7fc7a91d5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# Generate synthetic data\n",
    "fake = Faker()\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate 1000 samples\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    income = np.random.randint(20000, 100000)\n",
    "    debt = np.random.randint(0, 30000)\n",
    "    credit_history = np.random.randint(1, 20)\n",
    "    creditworthy = np.random.randint(0, 2)\n",
    "    data.append([income, debt, credit_history, creditworthy])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=['income', 'debt', 'credit_history', 'creditworthy'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('credit_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9194e7b1-4047-45f5-a23f-b931074fe699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faker\n",
      "  Downloading Faker-26.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 435.7 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/1.8 MB 656.4 kB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/1.8 MB 657.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.8 MB 544.7 kB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.1/1.8 MB 481.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.8 MB 500.5 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 506.0 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.2/1.8 MB 497.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 558.1 kB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.3/1.8 MB 589.5 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.8 MB 634.9 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.8 MB 634.9 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.3/1.8 MB 634.9 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.4/1.8 MB 624.4 kB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 0.5/1.8 MB 669.4 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 697.5 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 655.3 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.6/1.8 MB 667.6 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.7/1.8 MB 712.1 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.7/1.8 MB 720.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.7/1.8 MB 686.1 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 723.7 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 720.7 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 720.7 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.8 MB 699.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.8 MB 699.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.8 MB 639.5 kB/s eta 0:00:02\n",
      "   -------------------- ------------------- 0.9/1.8 MB 701.7 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 714.9 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 719.2 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.1/1.8 MB 738.9 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.1/1.8 MB 744.1 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.2/1.8 MB 753.4 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.8 MB 749.9 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.8 MB 754.4 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.8 MB 739.6 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 736.4 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 735.9 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 728.2 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 728.2 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.8 MB 713.1 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.8 MB 717.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.8 MB 705.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.8 MB 709.8 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.5/1.8 MB 703.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.8 MB 697.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 710.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 722.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.8 MB 739.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 751.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 739.0 kB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-26.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script faker.exe is installed in 'C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f62258-ce61-4982-bc6f-561534ef37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bffe6fb4-b416-49a5-ba59-2b9adac6c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income            0\n",
      "debt              0\n",
      "credit_history    0\n",
      "creditworthy      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\hp\\Documents\\credit_data.csv\")\n",
    "\n",
    "# Check for any missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('creditworthy', axis=1)\n",
    "y = df['creditworthy']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for models like SVM, but not always necessary for Random Forest)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1204784f-c6f0-4305-8682-308220075ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "903cd71d-e8de-47c5-94bb-46adb886aa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "Confusion Matrix:\n",
      "[[47 42]\n",
      " [50 61]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.51        89\n",
      "           1       0.59      0.55      0.57       111\n",
      "\n",
      "    accuracy                           0.54       200\n",
      "   macro avg       0.54      0.54      0.54       200\n",
      "weighted avg       0.54      0.54      0.54       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44258181-270c-44ea-8cff-fa43676fa7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for new applicant: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example prediction for a new applicant\n",
    "new_data = np.array([[50000, 10000, 5]])  # Example values for income, debt, and credit history\n",
    "new_data_scaled = scaler.transform(new_data)  # Scale the new data\n",
    "prediction = clf.predict(new_data_scaled)\n",
    "print(f'Predicted class for new applicant: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5059a7-0571-48e0-b7cd-b7d546545c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
